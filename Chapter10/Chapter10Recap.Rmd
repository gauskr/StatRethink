---
title: "Chapter 10: Recap"
author: "Guido Biele"
date: "11.05.2022"
output:
  html_document: 
    mathjax: default
    toc: true
    toc_depth: 2
    code_folding: hide
header-includes: 
    \usepackage{xcolor}
    \usepackage{amsmath}
---

  
```{css, echo = F}
body{
  font-family: Helvetica;
  font-size: 16pt;
  max-width: 1000px;
  margin: auto;
  margin-left:310px;
}
pre{
  font-size: 20px;
}
/* Headers */
h1{
    font-size: 24pt;
  }
h1,h2{
    font-size: 20pt;
  }
h3,h4,h5,h6{
  font-size: 18pt;
}

#TOC {
  position: fixed;
  left: 0;
  top: 0;
  width: 300px;
  height: 100%;
  overflow:auto;
}


```

```{r setup, include=FALSE, message=FALSE, warning=FALSE, results='hide'}
knitr::opts_chunk$set(echo = TRUE, dpi = 300, global.par = TRUE,
                      fig.align = 'center', out.width="80%")
library(rethinking)
library(magrittr)
library(knitr)
library(kableExtra)
library(MASS)
source("../utils.R")

set_par = function(mfrow = c(1,1), mar=c(3,3,.5,.5), cex = 1.25) 
  par(mfrow = mfrow, mar=mar, mgp=c(1.75,.5,0), tck=-.01, cex = cex)
```

# Generalized linear models

So far we have used linear regressions, where we modeled the outcome as follows:

$$
y \sim Normal(\mu,sigma) \\
\mu  = \alpha + \beta X
$$

This regression works generally well, even if $\small y$ is not normally distributed. (The residuals should be though. And a posterior predictive plot is always useful!)

## Distributions

However, for some outcome types a linear regression simply does not work. This is particularity clear when the outcome is bound to be equal to or larger than zero (like counts that "clump" at zero) or when the outcome is binary.

As an example the next figure shows end of year math grades in a Portuguese school.^[P. Cortez and A. Silva. Using Data Mining to Predict Secondary School Student Performance. In A. Brito and J. Teixeira Eds., Proceedings of 5th FUture BUsiness TEChnology Conference (FUBUTEC 2008) pp. 5-12, Porto, Portugal, April, 2008, EUROSIS, ISBN 978-9077381-39-7. Data can be downloaded [here](https://archive.ics.uci.edu/ml/datasets/Student+Performance)]

```{r out.width="80%", fig.height=4}
df=read.table("data/student-mat.csv",sep=";",header=TRUE)
df = df[df$Medu>0,]
set_par()
x = barplot(c(table(df$G3),0,0,0), xaxt = "n", border = "grey")
axis(1,at = x[seq(0,20,2)+1], labels = seq(0,20,2))
```


In these situations we can use this kind of model:

$$
y \sim dist(\theta_1,\theta_2) \\
$$

Here $\small dist(\theta_1,\theta_2)$ is a distribution with two parameters^[There are also distributions with 1 or 3 or more parameters] that is consistent with the observed data.

__Choosing a different distribution means choosing a different likelihood function__. That is, we exchange `dnomr` with an alternative distribution that is appropriate for the data.

Here are a few examples:

- The [Binomial distribution](https://en.wikipedia.org/wiki/Binomial_distribution) models the _"number of successes in a sequence of n independent experiments, each asking a yesâ€“no question"_. Hence we use the Binomial distribution function to calculate the likelihood of the data given model and parameters when we model number of successes. A special case is when we have only one trial / experiment, the Binomial distribution models binary outcomes.

```{r out.width="80%", fig.height=4}
set_par()
x = seq(0,5,1)
plot(x-.2,dbinom(x, 5, .2),"h", xlim = c(0,20), lwd = 2,
     ylab = "probability mass", xlab = "number of success")
x = seq(0,10,1)
lines(x,dbinom(x, 10, .5),"h", col = "blue", lwd = 2)
x = seq(0,20,1)
lines(x+.2,dbinom(x, 20, .75),"h", col = "red", lwd = 2)
legend("topright",
       lwd = 2, col = c("black","blue","red"),
       legend = c(
         expression(theta[1]~" = n = 5, "~theta[2]~" = p = .2"),
         expression(theta[1]~" = n = 10, "~theta[2]~" = p = .5"),
         expression(theta[1]~" = n = 30, "~theta[2]~" = p = .75")
       ),
       bty = "n")
```

- The [Poisson distribution](https://en.wikipedia.org/wiki/Poisson_distribution) _"expresses the probability of a given number of events occurring in a fixed interval of time or space if these events occur with a known constant mean rate"_ . Hence we use the Poisson distribution function to calculate the likelihood of the data given model and parameters when we occurrence of events (counts).

```{r, out.width="80%", fig.height=4}
set_par()
x = seq(0,5,1)
plot(x-.2,dpois(x, .5),"h", xlim = c(0,20), lwd = 2,
     ylab = "probability mass", xlab = "number of events")
x = seq(0,10,1)
lines(x,dpois(x, 5),"h", col = "blue", lwd = 2)
x = seq(0,20,1)
lines(x+.2,dpois(x, 10),"h", col = "red", lwd = 2)
legend("topright",
       lwd = 2, col = c("black","blue","red"),
       legend = c(
         expression(theta[1]~" = "~lambda~" = p =  .5"),
         expression(theta[1]~" = "~lambda~" = p = 5"),
         expression(theta[1]~" = "~lambda~" = p = 10")
       ),
       bty = "n")
```

## Link functions

As can be seen from the previous plots, the expected value (the mean parameter) of the Binomial and Poisson distributions are constrained:

- For the Binomial distribution:  $\small 0 \leq \textrm{success probability } p \leq 1$
- For the Poisson distribution:  $\small 0 \leq \textrm{expected rate } \lambda$.

But if we would just model e.g. 
$$
p =  \alpha + \beta X
$$
we could get values between minus and plus infinity. Therefore the generalized linear model also used link functions that map the result of the _linear predictor_ $\small \alpha + \beta X$ to the desired range:

$$
p = link(\alpha + \beta X)
$$

Different distribution use different link function to implement different constraints:

- Link function for the Binomial distribution: $\small p = inv.logit(\alpha + \beta X)$

$$
\small inv.logit(x) = \frac{1}{1+exp(-x)} = \frac{exp(x)}{1+exp(x)}
$$

```{r, out.width="80%", fig.height=4}
set_par()
curve(boot::inv.logit(x),-5.1,5.1,n = 100,
      xlab = expression(alpha~" + "~beta~"X"), ylab = "p")
```


- For the Poisson: $\lambda = exp(\alpha + \beta X)$

```{r, out.width="80%", fig.height=4}
```


```{r, out.width="80%", fig.height=4}
set_par()
curve(exp(x),-3,4,n = 100,
      xlab = expression(alpha~" + "~beta~"X"), ylab = expression(lambda))
```

One important effect of link functions is that we cannot interpret regression weights in the same way as for simple linear regression. In a nutshell, if link functions exponentiate the linear predictor, regression weights represent multiplicative rather than additive effects.

In `R` `family` is the term for an object that tells a regression model both what outcome distribution to use and what link function to use.

When do we use the Binomial and when the Poisson Likelihood?


- Poisson when there is no clear limit to the number of counts
  - number of apples in an orchard
  - number of people with a PhD
  - number of romantic partners per person

- Binomial when the counted number of success is limited by the number of trials. This is the reason that the Binomial distribution has 2 parameters.
  - number of people with a PhD that have red hair
  - number of Norwegian romantic partners per person
  
# Logistic regression

For a hands on example for logistic regression we will try to predict failing the math class with the Portugese school data shown above.
In particular, we will use these predictors:

- maternal education
- numbers of times the class was failed previously

It is always a good idea to plot the data first:

```{r out.width="80%", fig.height=4}
data.list = list(
  Medu = df$Medu,
  failures = df$failures,
  fail = df$G3 == 0
) 
set_par(mfrow = c(1,2))
table(data.list$Medu) %>% barplot(border = "grey", ylab = "count", xlab = "maternal edu")
table(data.list$failures) %>% barplot(border = "grey",   xlab = "number fails")
```

We are de-meaning `Medu`, so that the intercept measures odds of average maternal education.

```{r}
data.list$Medu = data.list$Medu-2.5
```

We beging the analysis with an intercept model only:

```{r}
model = alist(
  fail ~ dbinom(1,p),
  logit(p) <- a,
  a ~ dnorm(0,10)
)
```

## Prior predictive check

And we estimate the model with `ulam` (i.e. Stan):

```{r, warning=FALSE, message=FALSE, results='hide'}
u.fit_I = ulam(
  model,
  data = data.list,
  iter = 2000,      # 2000 iterations, (1000 warmup)
  chains = 4,       # four chains, to check convergence
  cores = 4,        # use 4 cores in parallel
  cmdstan = TRUE)   # use cmdstanr not rstan
```


We extract the prior and plot the prior prediction for the failure rate:

```{r warning=FALSE, message=FALSE, results='hide'}
prior = extract.prior(u.fit_I)
set_par()
hist(inv_logit(prior$a), main="")
```

To see what is going on here, lets overlay the logistic function on the prior:

```{r, out.width="100%", fig.height=4}
set_par(mfrow = c(1,2), mar=c(3,3,3,3), cex = 1)

curve(dnorm(x,0,10),-30,30, ylab = "prior density", xlab = "a")
axis(4,at = seq(0,0.04, length.out = 5),
     labels = seq(0,1,length.out = 5), col = "red")
curve(inv_logit(x)/25, add = T, col = "red")
abline(h = .1/25, lty = 3, col = "grey")
title("a ~ dnorm(0,10)")

curve(dnorm(x,0,2),-6,6, ylab = "prior density", xlab = "a")
axis(4,at = seq(0,0.2, length.out = 5),
     labels = seq(0,1,length.out = 5), col = "red")
curve(inv_logit(x)/5, add = T, col = "red")
abline(h = .1/5, lty = 3, col = "grey")
title("a ~ dnorm(0,2)")
```

With a wide prior, most of the probability mass is smaller than -5, leading to p very close to 0, or larger than 5, leading to p close to 1.


How about the regression coefficients $\small beta$? Regression coefficients are logg odds ratios.

For instance, lest assume the following:

- for highly educated parents, 2 out of 100 children fail the class
- for less educated parents, 4 out of 100 children fail the class

then the odds ratio is :

$$
\begin{align*}
OR = & \frac{\textrm{failure odds high edu}}{\textrm{failure odds low edu}} \\
= & \frac{\frac{2}{98}}{\frac{4}{96}} = \frac{.0204}{.0417} = .49
\end{align*}
$$

Note that this specific odd ratio comes close to the risk ratio of $\small .2 / .4 = .5$.

This is, however, not generally the case. If the probabilities are far away from zero, risk ratio and odds ratio do not align! We can see this if we just multiply the probability of failure by 15 in both groups:

$$
\begin{align*}
OR = \frac{\frac{30}{70}}{\frac{60}{40}} = \frac{.428}{.667} = .29
\end{align*}
$$

Lets go back to specifying our prior for $\small \beta$:

- We had an odds ration of 0.49, which corresponds to a log odds ratio of log(.49) ~ -.7. 
- This means that if we assume that that failure probability is low and a shift from high to low education comes with a doubling of class-fail probability, we should allow $\small \beta$ values of size .7.
- If we wanted to set an informative prior, which however does not prefer one direction of the effect, we could set a `dnorm(0,.7)` prior.
- But we are not so sure and don't like to informative priors, so we set a `dnorm(0,2)` prior.

Lest specify such a model and look at the prior predictions for the difference between two levels of education:


```{r warning=FALSE, message=FALSE, results='hide'}
model = alist(
  fail ~ dbinom(1,p),
  logit(p) <- a + b1*Medu,
  a ~ dnorm(0,2),
  b1 ~ dnorm(0,2)
)
u.fit_E = ulam(
  model,
  data = data.list,
  iter = 2000,      # 2000 iterations, (1000 warmup)
  chains = 4,       # four chains, to check convergence
  cores = 4,        # use 4 cores in parallel
  cmdstan = TRUE)   # use cmdstanr not rstan

prior = extract.prior(u.fit_E)
```

Now we can use the `link_ulam` function and new data to generate predictions from the prior. First we look at the effect of a one level change of education.

```{r out.width="100%", fig.height = 4}
p = link_ulam(
  u.fit_E, post = prior, 
  data = list(failures = c(0,0),
              Medu = c(0,1)))
set_par(mfrow = c(1,2), mar=c(3,3,3,3), cex = 1)
hist(p[,2]-p[,1],
     main = "risk difference", xlab = "P(fail|high) - P(fail|low)")
hist(p[,2]/p[,1], breaks = 30,
     main = "risk ratio", xlab = "P(fail|high) / P(fail|low)")
```

These differences and ratios are pretty large, so it is safe to make the prior a bit narrower and set the standard deviation for the regression weights to 1.

Here is the our model so far, which include previous class fails and maternal education as predictors: 

```{r  warning=FALSE, message=FALSE, results='hide'}
model = alist(
  fail ~ dbinom(1,p),
  logit(p) <- a + b1*Medu + b2*failures,
  a ~ dnorm(0,2),
  b1 ~ dnorm(0,1),
  b2 ~ dnorm(0,1)
)
u.fit_FE = ulam(
  model,
  data = data.list,
  iter = 2000,      # 2000 iterations, (1000 warmup)
  chains = 4,       # four chains, to check convergence
  cores = 4,        # use 4 cores in parallel
  cmdstan = TRUE)   # use cmdstanr not rstan
```


## Posterior predictive check

To see if our model describes the data well, we plot model predicted and observed data together:

```{r, out.width="100%", fig.height=6}
aggr.fun = function(x) return(c(mean = mean(x), N = length(x)))
obs = 
  aggregate(
  data.list$fail,
  by = with(data.list, 
            data.frame(Medu = Medu, failures = failures)), 
  aggr.fun
  )
obs = cbind(obs,obs$x)


sim.data = 
  unique(as.data.frame(data.list)[,1:2])

p = link_ulam(
  u.fit_FE,
  data = sim.data)

pp.stats = cbind(
  sim.data,
  m = colMeans(p),
  t(apply(p,2,PI))
)

set_par(mfrow = c(2,2), mar=c(3,3,1.5,0.5), cex = .75)
tmp = 
  lapply(unique(obs$Medu), function(x) {
  plot(obs[obs$Medu == x,"failures"],
       obs[obs$Medu == x,"mean"],
       cex = sqrt(obs[obs$Medu == x,"N"]),
       xlim = c(-.5,3.5), ylim = c(0,.5),
       ylab = "proportion fail",
       xlab = "# past failures",
       xaxt = "n", pch = 16, col = "grey")
    title(paste("maternal edu",x+1.5),line = 0.5, cex.main = 1)
    axis(1,at = 0:3)
    points(pp.stats[pp.stats$Medu == x,"failures"],
       pp.stats[pp.stats$Medu == x,"m"], pch = 16, col = "blue")
    arrows(pp.stats[pp.stats$Medu == x,"failures"],
           y0 = pp.stats[pp.stats$Medu == x,"5%"],
           y1 = pp.stats[pp.stats$Medu == x,"94%"],
           length = 0, col = "blue")
})



```



- posterior predictive checks

- contrasts

- odds ratios (relative vs absolute effects, relative risk, risk difference)


