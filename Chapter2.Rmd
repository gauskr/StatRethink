---
title: "Chapter 2"
author: "Guido Biele"
date: "03.03.2022"
output:
  html_document: 
    mathjax: default
    toc: true
    toc_depth: 2
header-includes: \usepackage{xcolor}
---

```{css, echo = F}
body{
  font-family: Helvetica;
  font-size: 16pt;
}
pre{
  font-size: 20px;
}
/* Headers */
h1,h2{
  font-size: 22pt;
}
h3,h4,h5,h6{
  font-size: 18pt;
}
```

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, dpi = 300)
```


The sections 

- What is conditional probability?
- Answer to exercise 2E3
- What are probability distribution, and where do we need them for Bayesian statistics?

are redundant with the background material for chapter 2.

# What is conditional probability?

Lets say you want to know if a random day in the year is a winter day, is a snow day, and what the relationship between winter and snow days is.

We start by drawing a circle, which symbolizes all days in a year:

```{r, echo = F}
library(plotrix)
par(mar = c(0,0,0,0))
pie(c(3,1), labels = "")
draw.circle(0,0,.8, col ="white")
```

This circle captures all 4 possible day types: winter days with and without snow and days in the other seasons with and without snow. The probability that a day belongs to any of these day types is 1. Therefor we say that the area of the circle is also 1.

We know that a quarter of the days in a year are in winter months. We visualize this by highlighting a section of the circle in icy blue.

```{r, echo = F}
draw_pie = function() {
  par(mar = c(0,0,0,0))
  pie(c(3,1), labels = "", border = "white")
  draw.circle(0,0,.8)
}
draw_pie()
```

From this we can see that the probability of winter is 1/4, or 0.25. This is an unconditional (or marginal) probability, and we can write $P(winter)$ = 0.25.

Snowy days are usually in winter. Therefore, we add an ellipse for snow days that largely overlaps with the quadrant for winter days.

```{r, echo = F}
draw_pie()
e.rot = 45
h.e = .25
k.e = -.25
a.e = .5
b.e = .175
draw_ellipse = function() {
  draw.ellipse(h.e,k.e,a.e,b.e , angle = e.rot,
               col = adjustcolor("grey",alpha = .75),
               border = adjustcolor("grey",alpha = .75)) 
}
draw_ellipse()
```

The unconditional (or marginal) probability of snow, $P(snow)$, is the probability of snow independent if it is winter or not, and corresponds to the area of the grey ellipse:  $P(snow) =$ 
`r pi*a.e*b.e/(pi*.8^2)`.

We can also use the figure above to explain what a joint probability is: The joint probability of winter and snow $P(winter, snow)$ or $P(winter \cap snow)$ is the ellipse-area that overlaps with the bottom right quadrant, which is shown in the next figure.

```{r, echo = F}
par(mar = c(0,0,0,0))
pie(c(3,1), labels = "")
draw.circle(0,0,.8, col ="white")
draw.ellipse(h.e,k.e,a.e,b.e , col = "lightblue", angle = e.rot, border = "lightblue")
draw_ellipse()
rect(0,0,.7,.2, col = "white", border = NA)
rect(0,0,-.2,-.7, col = "white", border = NA)
text(0,1,expression("P(snow,winter)" =="gray area"))
```

What is a conditional probability? A conditional probability gives the answer to the question "Given that it is winter, what is the probability of snow". This amounts to the question "What is the size of the ellipse-area that overlaps with the bottom right quadrant, _relative to_ the area of the bottom right quadrant". The next figure visualizes this.


```{r, echo = F}
par(mar = c(0,0,0,0))
pie(c(3,1), labels = "", border = "white")
draw.circle(0,0,.8)
text(0,1,expression("P(snow|winter)" == frac("gray area", "blue area")))
draw_ellipse()
rect(0,0,.7,.2, col = "white", border = NA)
rect(0,0,-.2,-.7, col = "white", border = NA)
```

To obtain a conditional probability, we are "conditioning" our question about the probability of snow on the value of another variable, namely that the season is winter. In comparison, the joint probability asks "What is the size of the trimmed ellipse-area, _relative to_ the total circle area of 1".

The following figure makes even clearer that the joint probability is the probability of snowy winter days divided by the probability of any day (which is just one), and that the conditional probability is the probability of snowy winter days divided by the probability of winter days. Note that because the probability of a winter day is smaller than 1 and dividing by a number smaller than one makes a number larger, dividing by the marginal probability of winter insures that the conditional probability is larger than the joint probability.

```{r, echo = F}
par(mar = c(0,0,0,0), mfrow = c(2,2))
pie(c(3,1), labels = "", ylim = c(0,-.5))
draw.circle(0,0,.9, col ="white", border = "white")
draw.ellipse(h.e,k.e,a.e,b.e , col = "lightblue", angle = e.rot, border = "lightblue")
draw_ellipse()
rect(0,0,.7,.2, col = "white", border = NA)
rect(0,0,-.2,-.7, col = "white", border = NA)
lines(c(-1,1),c(-1,-1), lwd = 2)
text(0,.7,"P(snow,winter)")

pie(c(3,1), labels = "")
draw.circle(0,0,.9, col ="white", border = "white")
draw_ellipse()
rect(0,0,.7,.2, col = "white", border = NA)
rect(0,0,-.2,-.7, col = "white", border = NA)
text(0,.7,"P(snow|winter)")
lines(c(-1,1),c(-1,-1), lwd = 2)

pie(c(3,1), labels = "")
draw.circle(0,0,.8, col ="white")


pie(c(3,1), labels = "", border = "white")
```


So, to calculate the conditional probability $P(snow|winter)$ we want to answer the question "What is the size of the ellipse-area that overlaps with the bottom right quadrant, _relative to_ the area of the bottom right quadrant". Unfortunately, there is no simple equation for calculating the overlap of an ellipse and a circle quadrant. But we can approximate the correct answer by randomly placing points into the circle and checking if they are in the bottom right quadrant (winter), in the ellipse (snow), or in the area of the ellipse that overlaps with the bottom right quadrant (winter and snow).

Here is the code for the simulation. You don't need to understand all of it, the important part is that we are keeping track of winter and snow days in the vectors with the names `is.winter` and `is.snow`, respectively. 

```{r, echo = F}
shift_rotate = function(xy,shift_x, shift_y, angle) {
  theta = 2*pi/(1/(angle/360))
  trans.mat = transf = matrix(c(cos(theta),-sin(theta),sin(theta),cos(theta)),nrow = 2)
  
  x.e = xy[1] - shift_x
  y.e = xy[2] - shift_y
  
  xy_transf = trans.mat %*% matrix(c(x.e,y.e))
  
  return(xy.r = c(
    x.r = shift_x + xy_transf[1],
    y.r = shift_y + xy_transf[2]  
  ))
}

in_ellipse = function(xy,h,k,a,b, e.rot) {
  xy.r = shift_rotate(xy,h,k,e.rot)
  (xy.r[1]-h)^2/a^2 + (xy.r[2]-k)^2/b^2 <= 1
}

rpoint_in_circle = function() {
  r = 0.8 * sqrt(runif(1))
  theta = runif(1) * 2 * pi
  return(c(0 + r * cos(theta),
           0 + r * sin(theta)))
}

```


```{r}
set.seed(123)
draw_pie()
draw_ellipse()

N = 365
is.winter = vector(length = N) # vector to count winter days
is.snow = vector(length = N) # vector to count snow days

for (k in 1:N) {
  # generate random point with custom function
  xy = rpoint_in_circle()
  
  # check if it is a snow day, i.e. in ellipse, with custom function
  is.snow[k] = in_ellipse(xy,h.e,k.e,a.e,b.e,e.rot)
  # check if it is a winter day
  is.winter[k] = xy[1] > 0 & xy[2] < 0
  
  # plot points
  points(xy[1],xy[2],
         pch = ifelse(is.snow[k] == T,8,21), cex = .75,
         bg = ifelse(is.winter[k] == T,"blue","red"),
         col = ifelse(is.winter[k] == T,"blue","red"))

}

legend(.75,.8,
       pch = c(8,21,15,15), bty = "n",
       col = c("black","black","blue","red"),
       legend = c("snow","no snow", "winter", "no winter"))
```

Let's first calculate the probability of winter, which should be around 0.25. This is simply the number of blue dots divided by the total number of dots.

```{r}
N_winter = sum(is.winter)
P_winter = N_winter/N
P_winter
```

Now, the probability of snow (star-shpaped dots divided by total number of dots):

```{r}
N_snow = sum(is.snow)
P_snow = N_snow/N
P_snow
```
And now it gets interesting. For the joint probability of winter and snow $P(winter, snow)$ we count the number of blue stars. 

```{r}
# logical indexing:
# is.snow[is.winter] returns only those entries of the 
# vector is.snow that are at positions where the 
# value for is.winter is TRUE
N_winter_and_snow = sum(is.snow[is.winter]) 
P_winter_and_snow = N_winter_and_snow/N
P_winter_and_snow
```

Check the last code block and see that to get the joint probability we divide by the total number of dots `N`.

In contrast, for conditional probabilities, we want to divide by the number of dots that have the value we are conditioning on. If we want to calculate the conditional probability $P(snow | winter)$, we therefore have to divide by the number of winter dots:

```{r}
P_snow_given_winter = N_winter_and_snow/N_winter
P_snow_given_winter
```

If you check further above, you can see that `P_winter_and_snow` and `P_winter` are calculated by dividing `N_winter_and_snow` and `N_winter` with `N`. Therefore, `N_winter_and_snow/N_winter` and `P_winter_and_snow/P_winter` have the same result and we can also write:

```{r}
P_snow_given_winter = P_winter_and_snow/P_winter
```

Hopefully, you recognize now that we have the conditional probability on the left side (`P_snow_given_winter` or $P(snow|winter)$), which we calculate with help of the joint probability (`P_winter_and_snow` or $P(snow, winter)$) and the unconditional (marginal) probability (`P_winter` or $P(winter)$) on the right side:

$$
\overset{\color{violet}{\text{conditional probability}}}{P(snow|winter)} = \frac{\overset{\color{red}{\text{joint probability}}}{P(snow, winter)}}{\overset{\color{blue}{\text{marginal probability}}}{P(winter)}}
$$

or more abstract:

$$
\overset{\color{violet}{\text{conditional probability}}}{P(A|B)} = \frac{\overset{\color{red}{\text{joint probability}}}{P(A, B)}}{\overset{\color{blue}{\text{marginal probability}}}{P(B)}}
$$
and by multiplying with $P(B)$ on both sides, we get 

$$
\overset{\color{red}{\text{joint probability}}}{P(A,B)} = \overset{\color{violet}{\text{conditional probability}}}{P(A|B)} \cdot \overset{\color{blue}{\text{marginal probability}}}{P(B)}
$$

which is the general product rule (or chain rule) that connects conditional probabilities with joint probabilities.

Can you also show that the following is true?

$$
P(A, B) = P(B|A) \cdot P(A)
$$

Or, using the example above

$$
P(snow, winter) = P(winter|snow) \cdot P(snow)
$$

## 2E1 Probabaility of rain on Monday

2 and 4 are correct. 

Why 4, P(rain, Monday) / P(Monday)?

We know generally that 

P(A,B) = P(A|B) * P(B) (page 37)

then 

P(rain, Monday) = P(rain | Monday) * P(Monday)

divide by P(Monday) on both sides

P(rain, Monday) / P(Monday) = P(rain | Monday)

## 2E2 What does Pr(Monday|rain) mean?

Probability of rain, given that it is Monday

3 is correct

## 2E3 Consistent with "probability of Monday given that it is raining"

1 and 4 are correct. Why 4?

1: P(Monday|rain)

4: P(rain|Monday) * P(Monday) / P(rain)

The question is then if we can show that 

$P(Monday|rain) = P(rain|Monday) \cdot P(Monday) / P(rain)$?

The key to the solution is that we can use both $P(Monday|rain)$ and $P(rain|Monday)$ to calculate the same thing: the joint probability of $P(Monday,rain)$.

Page 37 shows the relationship of joint and conditional probability:

$$
P(A,B) = \color{blue}{P(A|B) \cdot P(B)} \\
P(A,B) = \color{red}{P(B|A) \cdot P(A)}
$$

Therefore, we can say that the joint probability that it is Monday and raining is 

$$P(Monday,rain) = \color{blue}{P(rain|Monday) \cdot P(Monday)}$$

or

$$P(Monday,rain) = \color{red}{P(Monday|rain) \cdot P(rain)}$$
and we can further say 

$$
\color{red}{P(Monday|rain) \cdot P(rain)} = \color{blue}{P(rain|Monday) \cdot P(Monday)}
$$

If we want to know what P(Monday|rain) is, we now have to devide on both sides with P(rain), which gives us

$$
\color{red}{P(Monday|rain)} = \frac{\color{blue}{P(rain|Monday) \cdot P(Monday)}}{\color{red}{P(rain)}}
$$

where the right hand side is answer 4 from above.


Maybe the last equation looks familiar. To make it a bit more recognizable, we can replace Monday with $A$ and $rain$ with $B$:

$$
P(A|B) = \frac{P(B|A) \cdot P(A)}{P(B)}
$$
This is Bayes Rule, which one uses to calculate the inverse conditional probability, i.e. when we have information about the probability of $B$ given $A$ and want to calculate the probability of $A$ given $B$.


## 2E4 What does it mean to say "the probability of water is 0.7"?

It seems fair to describe Richard McElreath as a determinist which is 

> the philosophical view that all events are determined completely by previously existing causes^[https://en.wikipedia.org/wiki/Determinism]

This means that he takes the position^[in good company of many philosophers including Aristotle, Hobbes, Laplace or Daniel Dennet and physicists like Bohr and Einstein] that in principle everything is with certainty explainable, provided one has access to and can effectively use all relevant information. If everything is explainable, things happen or they don't, and therefor probability does not exist in nature.

However, limited information (and lack of Leviathan information processing) brings probability into existence for humans.

If a globe-tossing person would have all relevant information and computing power to calculate how a tossed globe moves through the air and is caught, she could say with certainty if the index finger would land on water and land, and therefore the probability of water would always be 1 or 0. Globe tossers who do not have the relevant information and computing power remain uncertain and express their uncertainty by stating with what probability the index finger will lang on water.

One consequence of this view is that the same situation can be deterministic for one person, and yet random for another person. For instance, random numbers generated with a computer are truly uncertain for somebody who does not know the "seed" number and the algorithm used to generate a random number. Such a person should make probabilistic statements about random numbers from the computer. In contrast, a person that know seed number and algorithm can make deterministic statements. For example, I know with certainty that if you execute the following command in R

```{r, eval = F}
set.seed(123)
runif(1) # random number between 0 and 1
```

that the resulting number will be smaller than 0.5. Other can only give a probability that the number is smaller than 0.5.

Probabilistic statements as expression of uncertainty can be related to, but are not the same as frequency-based statements. Frequency based statements come always from a countable event type: One has to count over multiple occurrences of an event to obtain frequencies. Thus, one could also arrive at the statement "the probability of water is 0.7" by tossing the globe multiple times. But we do not need to, we can also arrive at a probabilistic statement by starting with the fact that 70% of the earths surface is water.

Allowing probabilistic statements also for non-countable events is not uncontroversial. For instance, the classical NHST framework uses only frequencies. One motivation to still allow or use probabilistic statements about one-time events is that they make it possible to express uncertainty about one time events, e.g. the probability that we will have more then 5 hours cloudless sunshine one day from today in Oslo.

# What are probability distribution, and where do we need them for Bayesian statistics?

A probability distribution is a function that we use to describe a state of the world when we remain uncertain.

For such a function, we first need to be explicit what we are uncertain about. Continuing with the globe tossing example, we can say that we are uncertain about if we will catch the globe with the tip of the index finger on water. 

I we were sure to land on water, we would say $P(water) = 1$, and if we were sure to land on land, we would say $P(water) = 0$. But because we are uncertain, anything between 0 and 1 is possible. Therefore, our function to describe this uncertainty should allow values between 0 and 1. We can start drawing the function by just specifying an x axis that goes from 0 to 1.

```{r, echo = F}
plot(0, type = "n", xlim = c(0,1), 
     yaxt = "n", ylab = "", 
     xlab = "p",
     bty = "n")
```

Before we display uncertainty, let's look at how this function looks if we are certain to land on water:

```{r, echo = F}
plot(c(1,1),
     c(0,1),
     type = "l", xlim = c(0,1), 
     ylab = "density",
     xlab = "p",
     col = "blue",
     bty = "n")
```

If we are certain to land on water, $P(water)$ = 1 and all other probabilities have the value zero.

If we want to express uncertainty, we also have to allow for all other values. If we had no information whatsoever to say something about the probability to land on water, all probabilities should get the same value.

```{r, echo = F}
curve(dbeta(x,1,1),
      ylab = "density", 
      xlab = "p", 
      bty = "n",
      yaxt = "n")
```

For this function to be probability distribution, the area under the function (the integral) must sum up to 1.

To see this, we can observe in the next plot that the area under the probability function remains constant while we go from believing weakly (left) to more strongly (right) that the probability to land on water is larger than 0.5.

```{r, echo = F}
filled.beta = function(a = 1, b = 1, col = "blue", border = NA, ylim = NULL, add = F) {
  x = seq(0,1,.01)
  y = dbeta(x,a,b)
  x.poly <- c(x, tail(x,1), head(x,1))
  y.poly <- c(y, 0, 0)
  if (is.null(ylim)) ylim = c(0,max(y))
  if (add == FALSE)
    plot(0,type = "n", ylim = ylim, xlab = "p", ylab = "density", xlim = c(0,1), bty = "n")
  polygon(x.poly, y.poly, col=col, border=border)
}
par(mfrow = c(1,2))
filled.beta(1.3,1.1, col = adjustcolor("blue", alpha = .5), ylim = c(0,2))
curve(dbeta(x,1.3*2,1.1*1.5), col = adjustcolor("blue", alpha = .5), add = T)
filled.beta(1.3*2,1.1*1.5, col = adjustcolor("blue", alpha = .5), ylim = c(0,2))
curve(dbeta(x,1.3,1.1), col = adjustcolor("blue", alpha = .5), add = T)
```

To summarize, one can think of a probability distribution as a function that expresses how likely different values of a parameter (here p) are and who's area under the curve (or integral) is 1.

Depending on the nature of a parameter, different probability distributions must be used. Above, we use the so called beta distribution, because this distribution allows values between 0 and 1, which matches the fact that probabilities need to be between 0 and 1. For other phenomena different distributions can be used. For instance, we might want to use a normal distribution to characterize our uncertainty about tomorrow's temperature or a Poisson distribution to characterize uncertainty about things we count, like e.g. the number of shoes a person has.

In Bayesian statistics, we use such distributions to express three things:

1. <span style="color:blue">**Prior**</span> judgement about the probability of different parameter values before seeing the data. the parameter $p$ we introduced above describe the probability to land on water.
2. The probability of different parameter values given the data. This is also called the <span style="color:red">**likelihood**</span>
3. The <span style="color:violet">**posterior probability**</span> of different parameter values given our prior judgement and the data.

Lets walk through a simple example. We start by describing our prior judgement, we are slightly confident that we land rather on water,  with a beta distribution:

```{r, echo = F}
p = seq(0,1,length.out = 100)
prior = dbeta(p,2,1.5)
prior = prior/sum(prior)
plot(p,
     prior,
     type = 'l',
     xlab = "p",
     bty = "n",
     col = "blue")
```

Next the likelihood. For the globe tossing example, we can think of each toss as a trial and of each landing on the index finger as a success. The distribution the gives the likelihood of different success probabilities $p$ given a number of trials and successes is the binomial distribution. so we use this distribution to get the likelihood function. Lets assume we had 4 trials and 3 successes.

```{r, echo = F}
trials = 4
successes = 3
likelihood = dbinom(successes,size = trials, prob = p)
likelihood = likelihood/sum(likelihood)
plot(p,
     likelihood,
     type = 'l',
     xlab = "p",
     bty = "n",
     col = "red")
```

Now lets re-introduce Bayes rule, which we described above as:

$$
P(A|B) = \frac{P(B|A) \cdot P(A)}{P(B)}
$$

If we just replace $A$ with $parameter$ and $B$ with $data$ and annotate the different terms we get

$$
\overset{\color{violet}{\text{posterior probability}}}{P(parameter|data)} = \frac{\overset{\color{red}{\text{likelihood}}}{P(data|parameter)} \cdot \overset{\color{blue}{\text{prior probability}}}{P(parameter)}}{\overset{\color{orange}{\text{evidence}}}{P(data)}}
$$

This shows us that if we just multiply the likelihood with the prior, two things we just calculated and plotted above, we get something that is proportional to the posterior probability of the parameter (probability to land on water with the index finger on water) given the data.

Lets just calculate this: 

```{r, echo = F}
posterior = prior * likelihood
plot(p,
     posterior,
     type = 'l',
     xlab = "p",
     bty = "n",
     col = "violet",
     lwd = 2)
```

This distribution is only proportional to the posterior distribution, because the product of posterior and likelihood does not sum up to 1. We can calculate the posterior probability distribution by dividing by the sum. The next plot shows the the posterior distribution together with the prior distribution and the likelihood.


```{r, echo = F}
posterior = prior * likelihood
posterior = posterior/sum(posterior)
plot(p,
     posterior,
     type = 'l',
     xlab = "p",
     col = "violet",
     lwd = 2)
lines(p,prior,col = "blue")
lines(p,likelihood,col = "red")
```

The figure shows that the posterior is a compromise between the prior distribution and the likelihood. That is, it is a compromise between our information before we saw the data and the information that is in the data.

Because we had relatively little data compared to the information in the data, we can still clearly see the influence of the prior in the posterior. However, if we collect five times the data, we become more certain (the posterior distribution is narrower) and the influence of the prior is diminished so that the posterior will be very similar to the likelihood:

```{r, echo = F}
trials = 20
successes = 15
likelihood = dbinom(successes,size = trials, prob = p)
likelihood = likelihood/sum(likelihood)
posterior = prior * likelihood
posterior = posterior/sum(posterior)
plot(p,
     posterior,
     type = 'l',
     xlab = "p",
     col = "violet",
     lwd = 2)
lines(p,prior,col = "blue")
lines(p,likelihood,col = "red")
```


## 2M1 Grid posterior

### W-W-W
You need to use a sufficiently fine-grained grid to make differences visible.

```{r 2M1a}
# parameter values at which we calculate the posterior probability
p_H2O_grid = seq(from=0 , to=1, length.out=100)
# likelihood of 3 water in 3 tosses
N_tosses = 3
N_water = 3
likelihood = dbinom(N_water , size=N_tosses, prob=p_H2O_grid)
# uniform prior
prior = rep(1,100) 
posterior = likelihood * prior
sum(posterior)
plot(p_H2O_grid, posterior , type="l" , ylab = "density", xlab = "p")
# standardize 
posterior = posterior / sum(posterior)
sum(posterior)
```

We use R's `plot` command to show the results:
```{r 2M1b}
plot(p_H2O_grid, posterior , type="l", ylab = "density", xlab = "p" )
# this also works
# plot( posterior ~ p_H2O_grid , type="l" )
# personally, I prefer the plot(x_values, y_values) syntax
```

### W-W-W-L
For 4 tosses and 3 W.
```{r 2M1c}
likelihood = dbinom( 3 , size=4 , prob=p_H2O_grid )
posterior = likelihood * prior
posterior = posterior / sum(posterior)
plot(p_H2O_grid, posterior , type="l" , ylab = "density", xlab = "p")
```

### W-W-W-W-W-L-L
For 7 tosses and 5 W.
```{r 2M1d}
likelihood = dbinom( 5 , size=7 , prob=p_H2O_grid )
posterior = likelihood * prior
posterior = posterior / sum(posterior)
plot(p_H2O_grid, posterior , type="l" )
```

## 2M2 Modified priors

```{r 2M2}
prior[p_H2O_grid < .5] = 0

posterior = dbinom( 3 , size=3 , prob=p_H2O_grid ) * prior
posterior = posterior / sum(posterior)
plot(p_H2O_grid, posterior , type="l" , ylab = "density", xlab = "p")

posterior = dbinom( 3 , size=4 , prob=p_H2O_grid ) * prior
posterior = posterior / sum(posterior)
plot(p_H2O_grid, posterior , type="l" , ylab = "density", xlab = "p")

posterior = dbinom( 5 , size=7 , prob=p_H2O_grid ) * prior
posterior = posterior / sum(posterior)
plot(p_H2O_grid, posterior , type="l", ylab = "density", xlab = "p" )

``` 

## 2M3 Pr(Earth|land)

P(Earth | land) = .23 ? 

We know that 

- P(land | Earth) = 1 - P(water | Eart) = .3
- P(land | Mars) = 1
- P(Earth) = .5

We want to use
$$
P(A|B) = \frac{P(B|A) \cdot P(A)}{P(B)}
$$
A = Earth
B = land

so

$$
P(Earth|land) = \frac{P(land|Earth) \cdot P(Earth)}{P(land)}
$$

We know

- P(B|A) = P(land | Earth) = .3
- P(A) = P(Earth) = .5

But we are missing P(B) = P(land)

P(land) = (P(land | Earth) + P(land | Mars)) / 2 = .65


P(Earth | land) = P(land | Earth) * P(Earth) / P(land)

```{r 2M3}
.3 * .5 / .65
```

## 2M4 Probability that the back side is black with decks BB, BW, WW

We make a table with possible outcomes
```{r 2M4a, message=FALSE, warning=FALSE}
library(dplyr)  # for data manipulation
library(magrittr) # for pipes
library(knitr) # to show tables in Markdown
library(kableExtra) # for prettier tables
counts = 
  data.frame(
    Up =   c("B","B","B","W","W","w"),
    Down = c("B","B","W","B","W","W"))

kable(counts) %>% 
  kable_styling(full_width = F)
```

We keep only the rows where the up side is black and count how many of those are also black on the other side.

```{r 2M4b, message=FALSE}
counts %>% 
  filter(Up == "B") %>% 
  pull(Down) %>% 
  table() %>% 
  prop.table()
```

Just for fun, here is the data.table way:

```{r 2M4c, message=FALSE}
library(data.table)
data.table(
  Up =   c("B","B","B","W","W","w"),
  Down = c("B","B","W","B","W","W"))  %>%
  .[Up == "B"] %>% # dplyr: filter(Up == "B")
  .[, Down] %>%    # dplyr: pull(Down) %>% 
  table() %>% 
  prop.table()
```

## 2M5 Probability that the back side is black with decks BB, BB, BW, WW

We are just adding one BB card

```{r 2M5, message=FALSE}
library(data.table)
data.table(
  Up =   c("B","B","B","B","B","W","W","w"),
  Down = c("B","B","B","B","W","B","W","W"))  %>%
  .[Up == "B"] %>% 
  .[, Down] %>% 
  table()  %>% 
  prop.table()
```

## 2M6 Probability that the back side is black with heavy black

We use the `rep` command to manipulate the probability with which the different cards are chosen.

```{r 2M6, message=FALSE}
library(data.table)
data.table(
  Up =   c(rep(c("B","B"),1),
           rep(c("B","W"),2),
           rep(c("W","w"),3)),
  Down = c(rep(c("B","B"),1),
           rep(c("W","B"),2),
           rep(c("W","w"),3)))  %>%
  .[Up == "B"] %>% 
  .[, Down] %>% 
  table() %>% 
  prop.table()
```

## 2M7 Probability that the back side is black given that a 2nd card shows white

There are 3 ways to draw a black face up: 

- Face 1 from BB
- Face 2 from BB
- Face 1 from BW

When we start with a black face from BB, there are three ways to have a white face up on the second card:

- Face 1 from WW
- Face 2 from WW
- Face 2 from BW

When we start with a black face from BW, there are two ways to have a white face up on the second card:

- Face 1 from WW
- Face 2 from WW

We are using the `expand.grid` function to generate combinations of draws.

```{r 2M7a}
BB_ways = 
  expand.grid(Black_up = c("BB","BB"),
              White_up = c("WB","WW","WW"))

BW_ways = 
  expand.grid(Black_up = c("BW"),
              White_up = c("WW","WW"))

all_ways = 
  rbind(
    BB_ways,
    BW_ways
  ) 

kable(all_ways) %>% 
  kable_styling(full_width = F)
  
```

and we count how often the down face of the "Black_up" cards is also black.

```{r 2M7b}
all_ways %>% 
  data.frame() %>% 
  rowwise() %>% 
  mutate(face_down = substr(Black_up,2,2)) %>% 
  pull(face_down) %>% 
  table() %>% 
  prop.table()
```

_COMMENT: ARE THERE OTHER “EASIER” SOLUTIONS TO GET THE SAME CONCLUSION????_

GB: Not any I can immediately think of.

# Clarification questions

When to use probability versus plausibility? Are these words interchangeable? What about Pr vs. p?

Can you say something more about the usage of words “likelihood” and “distribution function” in Bayesian vs frequentist statistics? (ref section 2.3.2.1 on p. 33)


# Exercises for next time:

Everyone 3E1 - 3M6

Why so many excersises?

- 3E1 - 3E7 are easy / fast.
- 3M1 - 3M3 Build on each other
- 3M4, 3M5 just re-use the code from 3M1 - 3M3


General comments:

Please ...

- add the name of the team as author
- try to be more wordy, explain your code and/or use declarative variable names. (It is not suffient just to write the answers ;-))
- try to write down the solutions so that it will be easy to explain to others what you did.
- please submit compiled html files and not R-Markdown files (and check if the compiled html looks OK: line separation, plots shown etc)
- send your asnwers only once
- next time, every team  submit a clarification question or a discussion question

Rpubs:

- I propose we try to use Rpubs (https://rpubs.com/), i.e. you can submit a link to an Rpubs site. You can delete you post after the class.